chart.Boxplot(apply.monthly(returns, Return.cumulative))
charts.RollingPerformance(apply.monthly(returns, Return.cumulative))
chart.RiskReturnScatter(returns, add.sharpe = TRUE, Rf=.0071)
chart.RelativePerformance(apply.weekly(returns, Return.cumulative), apply.weekly(market_returns, Return.cumulative), legend.loc='topright')
chart.RollingRegression(apply.monthly(returns, Return.cumulative), apply.monthly(market_returns, Return.cumulative), legend.loc='bottomright')
############ Exploratory Analysis ############
#### Graphs ####
charts.PerformanceSummary(returns,main='Portfolio Assets Summary', rf=.0071)
#rm(list=ls())
############ Setup ############
#### Libraries ####
library(quantmod)
library(timeSeries)
library(fPortfolio)
library(PerformanceAnalytics)
library(ggplot2)
library(PerformanceAnalytics)
# Bootstrapping
library(mosaic)
# Optimization
library(PortfolioAnalytics)
library(DEoptim)
library(ROI)
require(ROI.plugin.glpk)
require(ROI.plugin.quadprog)
#### Get Returns ####
# Portfolio
tickers <- c("AGG", "GLD", "VUG")
# Get AdjClose prices
adjClosePrices <- NULL
for (ticker in tickers){
adjClosePrices <- cbind(adjClosePrices,
quantmod::getSymbols(ticker, from="2015-08-01", to = '2020-08-01', verbose=FALSE, auto.assign=FALSE)[,6])
}
# keep only the dates that have closing prices for all tickers
adjClosePrices <- adjClosePrices[apply(adjClosePrices,1,function(x) all(!is.na(x))),]
# Convert AdjClose to Returns
returns <- Return.calculate(adjClosePrices)[-1,1:length(tickers)]
############ Construct Portfolios ############
#### Portfolio 1 ####
port1_weights <- c(0.8, 0.15, 0.05)
# Create portfoli (Rebalancing Daily)
port1_returns <- Return.portfolio(returns, weights = port1_weights, rebalance_on = "days")
#### Portfolio 2 ####
port2_weights <- c(0.1, 0.2, 0.7)
# Create portfoli (Rebalancing Daily)
port2_returns <- Return.portfolio(returns, weights = port2_weights, rebalance_on = "days")
#### Portfolio 3 ####
portfolioAssets <- colnames(returns)
init <- portfolio.spec(assets=portfolioAssets)
# Add Constraint (Weights sum to 1, ie full investment)
init <- add.constraint(portfolio=init,
type="weight_sum",
min_sum=1,
max_sum=1)
# Add Constraint (No shorting or borrowing, and no over/under investment)
init <- add.constraint(portfolio=init,
type="box",
min=0.05,
max=0.5
)
# Add Constraint (Target Return = 10% annual, 0.00055% daily)
init <- add.constraint(portfolio=init, type="return", return_target=0.00055)
# Add Objective (Minimize risk)
minvar <- add.objective(portfolio=init,
type='risk',
name='var'
)
# Optimize Portfolio
opt_maxret <- optimize.portfolio(R=returns, portfolio=minvar,
optimize_method="ROI",
trace=FALSE
)
# Create portfoli (Rebalancing Daily)
port3_returns <- Return.portfolio(returns, weights = opt_maxret$weights, rebalance_on = "days")
#### Bench Mark Portfolio ####
tickers <- c("SPY")
# Get AdjClose prices
adjClosePrices <- NULL
for (ticker in tickers){
adjClosePrices <- cbind(adjClosePrices,
quantmod::getSymbols(ticker, from="2015-08-01", to = '2020-08-01', verbose=FALSE, auto.assign=FALSE)[,6])
}
# keep only the dates that have closing prices for all tickers
adjClosePrices <- adjClosePrices[apply(adjClosePrices,1,function(x) all(!is.na(x))),]
# Convert AdjClose to Returns
#returns <- as.timeSeries((tail(adjClosePrices,-1) / as.numeric(head(adjClosePrices,-1)))-1)
market_returns <- Return.calculate(adjClosePrices)[-1,]
############ VaR Calculation ############
#### Conceptual ####
conceptualCaR <- function(portfolio, confidence){
portfolio_resampled <- mosaic::resample(portfolio)
portfolioReturns <- coredata(portfolio_resampled$portfolio.returns)
sortedPortfolioReturns <- sort(portfolioReturns, decreasing=FALSE)
port_dailyVar <- quantile(sortedPortfolioReturns,c(confidence))
port_monthlyVaR <- port_dailyVar*sqrt(20)
return(port_monthlyVaR)
}
# Analysis (Port 1)
# Bootstrap
monthlyVaR_bootstrap = do(1000)*conceptualCaR(port1_returns,.05)
port1_montlyVaR <- mean(monthlyVaR_bootstrap$X5.)
# Analysis (Port 2)
# Bootstrap
monthlyVaR_bootstrap = do(1000)*conceptualCaR(port2_returns,.05)
port2_montlyVaR <- mean(monthlyVaR_bootstrap$X5.)
# Analysis (Port 3)
# Bootstrap
monthlyVaR_bootstrap = do(1000)*conceptualCaR(port3_returns,.05)
port3_montlyVaR <- mean(monthlyVaR_bootstrap$X5.)
#### Normal ####
# Analysis (Port 1)
# Bootstrap
dailyVaR_bootstrap = do(1000)*PerformanceAnalytics::VaR(mosaic::resample(port1_returns))
port1_montlyVaR <- mean(dailyVaR_bootstrap$VaR)*sqrt(20)
# Analysis (Port 2)
# Bootstrap
dailyVaR_bootstrap = do(1000)*PerformanceAnalytics::VaR(mosaic::resample(port2_returns))
port2_montlyVaR <- mean(dailyVaR_bootstrap$VaR)*sqrt(20)
# Analysis (Port 3)
# Bootstrap
dailyVaR_bootstrap = do(1000)*PerformanceAnalytics::VaR(mosaic::resample(port3_returns))
port3_montlyVaR <- mean(dailyVaR_bootstrap$VaR)*sqrt(20)
#### Graphing ####
# Returns
port1_monthly = apply.weekly(port1_returns, Return.cumulative)
port1 <- data.frame(port1_monthly)
port1$portfolio <- 'Portfolio 1'
sharpeRatio_port1 = (histRet_port1-rf_monthly)/(risk_port1)
charts.RollingPerformance(apply.monthly(returns, Return.cumulative))
chart.Boxplot(apply.monthly(returns, Return.cumulative))
charts.RollingPerformance(apply.monthly(returns, Return.cumulative))
chart.RiskReturnScatter(returns, add.sharpe = TRUE, Rf=.0071)
chart.RelativePerformance(apply.weekly(returns, Return.cumulative), apply.weekly(market_returns, Return.cumulative), legend.loc='topright')
# get rid of scientific notation
options(scipen=999)
library(magrittr)
# read in data set
greenData <- read.csv("greenbuildings.csv")
View(greenData)
# separate into green and non-green buildings
greenBuildings <- greenData %>% filter(green_rating == 1)
nonGreenBuildings <- greenData %>% filter(green_rating == 0)
library(magrittr)
# get rid of scientific notation
options(scipen=999)
# read in data set
greenData <- read.csv("greenbuildings.csv")
# separate into green and non-green buildings
greenBuildings <- greenData %>% filter(green_rating == 1)
nonGreenBuildings <- greenData %>% filter(green_rating == 0)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
subset_All <- greenData %>% filter(amenities==1,
cd_total_07>=966,
stories<=20,
stories>=10,
age<=10 | renovated==1)
subset_Green <- subset_All %>% filter(green_rating==1)
subset_Nongreen <- subset_All %>% filter(green_rating==0)
subset_All <- greenData %>% filter(amenities==1,
cd_total_07>=966,
stories<=20,
stories>=10,
age<=10 | renovated==1)
nonGreenBuildings <- greenData %>% filter(green_rating == 0)
# separate into green and non-green buildings
greenBuildings <- greenData %>% filter(green_rating == 1)
nonGreenBuildings <- greenData %>% filter(green_rating == 0)
subset_All <- greenData %>% filter(amenities==1,
cd_total_07>=966,
stories<=20,
stories>=10,
age<=10 | renovated==1)
# Subset Green Buildings, ~15 stories (+-5 stories), new (built within last 5 years)
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10,
amenities==1,
cd_total_07>=966)
###
subset_All <- greenData %>% filter(amenities==1,
cd_total_07>=966,
stories<=20,
stories>=10,
age<=10 | renovated==1)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10,
amenities==1,
cd_total_07>=966)
library(mosaic)
library(dplyr)
library(ggplot2)
library(magrittr)
greenData <- read.csv('greenbuildings.csv')
# Subset into just green buildings (Green Buildings: Rent)
greenBuildings <- greenData %>% filter(green_rating == 1)
# Subset Green Buildings, ~15 stories (+-5 stories), new (built within last 5 years)
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10,
amenities==1,
cd_total_07>=966)
# Subset into just green buildings (Green Buildings: Rent)
greenBuildings <- greenData %>% filter(green_rating == 1)
# Subset Green Buildings, ~15 stories (+-5 stories), new (built within last 5 years)
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10,amenities==1,cd_total_07>=966)
# Subset Green Buildings, ~15 stories (+-5 stories), new (built within last 5 years)
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10)
# Subset Green Buildings, ~15 stories (+-5 stories), new (built within last 5 years)
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10,
amenities=='1',
cd_total_07>=966)
###
subset_All <- greenData %>% filter(amenities==1,
cd_total_07>=966,
stories<=20,
stories>=10,
age<=10 | renovated==1)
# separate into green and non-green buildings
greenBuildings <- greenData %>% filter(green_rating == 1)
nonGreenBuildings <- greenData %>% filter(green_rating == 0)
subset_All <- greenData %>% filter(amenities==1,
cd_total_07>=966,
stories<=20,
stories>=10,
age<=10 | renovated==1)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10,
amenities == 1,
cd_total_07 >= 966)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10,
amenities == 1,
cd_total_07 >= 966)
help(filter)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
greenBuildings_Ideal <- greenData %>% filter(.preserve = FALSE, green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10,
amenities == 1,
cd_total_07 >= 966)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1,
stories <= 20,
stories >= 10,
age >= 0,
age <= 10)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1&
stories <= 20&
stories >= 10&
age >= 0&
age <= 10)&
amenities == 1&
cd_total_07 >= 966)
# create subset of similar buildings based on what we know:
# mixed use building so look at buildings with amenities = 1
# new building so filter on buildings <10 yrs or renovated
# 15 stories so filter on buildings between 10-20 stories
# Austin, TX so filter on buildings with num cooling days > median of 966
greenBuildings_Ideal <- greenData %>% filter(green_rating == 1&
stories <= 20&
stories >= 10&
age >= 0&
age <= 10&
amenities == 1&
cd_total_07 >= 966)
subset_All <- greenData %>% filter(amenities==1&
cd_total_07>=966&
stories<=20&
stories>=10&
age<=10 | renovated==1)
# plot leasing rate vs size (all data)
ggplot(data = greenData) +
geom_point(aes(x = leasing_rate, y = size, color=factor(green_rating))) +
labs(color = "Green Building") +
# add colors and legend labels
scale_colour_manual(values = c("#01148A","#0AD626"),labels = c("No","Yes")) +
ggtitle("Leasing Rate vs. Size") +
# center plot title
theme(plot.title = element_text(hjust = 0.5))+
labs(x = "Leasing Rate",y = "Size (Sq. ft)")
plot(density(greenBuildings$Rent), main="Rent Distribution, All Buildings", ylim=c(0,.045), col = "#0AD626", xlab = "Rent Per Square Foot")
#rm(list=ls())
############ Setup ############
#### Libraries ####
library(quantmod)
library(timeSeries)
library(fPortfolio)
library(PerformanceAnalytics)
library(ggplot2)
library(PerformanceAnalytics)
# Bootstrapping
library(mosaic)
# Optimization
library(PortfolioAnalytics)
library(DEoptim)
library(ROI)
require(ROI.plugin.glpk)
require(ROI.plugin.quadprog)
#### Get Returns ####
# Portfolio
tickers <- c("AGG", "GLD", "VUG")
# Get AdjClose prices
adjClosePrices <- NULL
for (ticker in tickers){
adjClosePrices <- cbind(adjClosePrices,
quantmod::getSymbols(ticker, from="2015-08-01", to = '2020-08-01', verbose=FALSE, auto.assign=FALSE)[,6])
}
# keep only the dates that have closing prices for all tickers
adjClosePrices <- adjClosePrices[apply(adjClosePrices,1,function(x) all(!is.na(x))),]
# Convert AdjClose to Returns
returns <- Return.calculate(adjClosePrices)[-1,1:length(tickers)]
############ Construct Portfolios ############
#### Portfolio 1 ####
port1_weights <- c(0.8, 0.15, 0.05)
# Create portfoli (Rebalancing Daily)
port1_returns <- Return.portfolio(returns, weights = port1_weights, rebalance_on = "days")
#### Portfolio 2 ####
port2_weights <- c(0.1, 0.2, 0.7)
# Create portfoli (Rebalancing Daily)
port2_returns <- Return.portfolio(returns, weights = port2_weights, rebalance_on = "days")
#### Portfolio 3 ####
portfolioAssets <- colnames(returns)
init <- portfolio.spec(assets=portfolioAssets)
# Add Constraint (Weights sum to 1, ie full investment)
init <- add.constraint(portfolio=init,
type="weight_sum",
min_sum=1,
max_sum=1)
# Add Constraint (No shorting or borrowing, and no over/under investment)
init <- add.constraint(portfolio=init,
type="box",
min=0.05,
max=0.5
)
# Add Constraint (Target Return = 10% annual, 0.00055% daily)
init <- add.constraint(portfolio=init, type="return", return_target=0.00055)
# Add Objective (Minimize risk)
minvar <- add.objective(portfolio=init,
type='risk',
name='var'
)
# Optimize Portfolio
opt_maxret <- optimize.portfolio(R=returns, portfolio=minvar,
optimize_method="ROI",
trace=FALSE
)
# Create portfoli (Rebalancing Daily)
port3_returns <- Return.portfolio(returns, weights = opt_maxret$weights, rebalance_on = "days")
#### Bench Mark Portfolio ####
tickers <- c("SPY")
# Get AdjClose prices
adjClosePrices <- NULL
for (ticker in tickers){
adjClosePrices <- cbind(adjClosePrices,
quantmod::getSymbols(ticker, from="2015-08-01", to = '2020-08-01', verbose=FALSE, auto.assign=FALSE)[,6])
}
# keep only the dates that have closing prices for all tickers
adjClosePrices <- adjClosePrices[apply(adjClosePrices,1,function(x) all(!is.na(x))),]
# Convert AdjClose to Returns
#returns <- as.timeSeries((tail(adjClosePrices,-1) / as.numeric(head(adjClosePrices,-1)))-1)
market_returns <- Return.calculate(adjClosePrices)[-1,]
chart.RollingRegression(apply.monthly(returns, Return.cumulative), apply.monthly(market_returns, Return.cumulative), legend.loc='bottomright')
############ VaR Calculation ############
#### Conceptual ####
conceptualCaR <- function(portfolio, confidence){
portfolio_resampled <- mosaic::resample(portfolio)
portfolioReturns <- coredata(portfolio_resampled$portfolio.returns)
sortedPortfolioReturns <- sort(portfolioReturns, decreasing=FALSE)
port_dailyVar <- quantile(sortedPortfolioReturns,c(confidence))
port_monthlyVaR <- port_dailyVar*sqrt(20)
return(port_monthlyVaR)
}
# Analysis (Port 1)
# Bootstrap
monthlyVaR_bootstrap = do(1000)*conceptualCaR(port1_returns,.05)
port1_montlyVaR <- mean(monthlyVaR_bootstrap$X5.)
# Analysis (Port 2)
# Bootstrap
monthlyVaR_bootstrap = do(1000)*conceptualCaR(port2_returns,.05)
port2_montlyVaR <- mean(monthlyVaR_bootstrap$X5.)
# Analysis (Port 3)
# Bootstrap
monthlyVaR_bootstrap = do(1000)*conceptualCaR(port3_returns,.05)
port3_montlyVaR <- mean(monthlyVaR_bootstrap$X5.)
#### Normal ####
# Analysis (Port 1)
# Bootstrap
dailyVaR_bootstrap = do(1000)*PerformanceAnalytics::VaR(mosaic::resample(port1_returns))
port1_montlyVaR <- mean(dailyVaR_bootstrap$VaR)*sqrt(20)
# Analysis (Port 2)
# Bootstrap
dailyVaR_bootstrap = do(1000)*PerformanceAnalytics::VaR(mosaic::resample(port2_returns))
port2_montlyVaR <- mean(dailyVaR_bootstrap$VaR)*sqrt(20)
# Analysis (Port 3)
# Bootstrap
dailyVaR_bootstrap = do(1000)*PerformanceAnalytics::VaR(mosaic::resample(port3_returns))
port3_montlyVaR <- mean(dailyVaR_bootstrap$VaR)*sqrt(20)
#### Graphing ####
# Returns
port1_monthly = apply.weekly(port1_returns, Return.cumulative)
port1 <- data.frame(port1_monthly)
port1$portfolio <- 'Portfolio 1'
port2_monthly = apply.weekly(port2_returns, Return.cumulative)
port2 <- data.frame(port2_monthly)
port2$portfolio <- 'Portfolio 2'
port3_monthly = apply.weekly(port3_returns, Return.cumulative)
port3 <- data.frame(port3_monthly)
port3$portfolio <- 'Portfolio 3'
portfolioReturns <- rbind(port1, port2, port3)
# Portfolio VaRs
port1_VaR <- data.frame(PortfolioVaR=port1_montlyVaR)
port1_VaR$portfolio <- 'Portfolio 1'
port2_VaR <- data.frame(PortfolioVaR=port2_montlyVaR)
port2_VaR$portfolio <- 'Portfolio 2'
port3_VaR <- data.frame(PortfolioVaR=port3_montlyVaR)
port3_VaR$portfolio <- 'Portfolio 3'
portfolioVaRs <- rbind(port1_VaR, port2_VaR, port3_VaR)
ggplot(portfolioReturns, aes(portfolio.returns, fill = portfolio)) +
geom_density(alpha = 0.2) +
geom_vline(data=portfolioVaRs, aes(xintercept=PortfolioVaR, color = portfolio), linetype="dashed") +
ggtitle("Historical Returns (Monthly) vs VaR") +
xlab("Returns")
